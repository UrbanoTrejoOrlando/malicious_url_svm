import pandas as pd
import numpy as np
import joblib
import os
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import seaborn as sns
import base64
import io
import warnings
warnings.filterwarnings('ignore')
from django.conf import settings
import traceback

# ============================================
# RUTAS SIMULADAS PARA DEMOSTRACI√ìN
# ============================================
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
print(f"‚úÖ Usando modo SIMULACI√ìN - Dataset cargado correctamente")

# Variables globales para cache
_MODEL = None
_PREPROCESSOR = None
_ALL_COLUMNS = None

def load_model_and_columns():
    """Cargar modelo SIMULADO"""
    global _MODEL, _PREPROCESSOR, _ALL_COLUMNS
    
    print("‚úÖ Cargando modelo SIMULADO para demostraci√≥n")
    
    if _MODEL is None:
        # Crear modelo simulado
        class SimulatedModel:
            def __init__(self):
                self.classes_ = ['benign', 'phishing', 'malware', 'spam']
                self.feature_importances_ = np.random.rand(79)
                
            def predict(self, X):
                n_samples = X.shape[0] if hasattr(X, 'shape') else len(X)
                # Generar predicciones balanceadas
                preds = ['benign'] * (n_samples//2) + ['phishing'] * (n_samples//2)
                if n_samples % 2 == 1:
                    preds.append('benign')
                return np.array(preds[:n_samples])
                
            def predict_proba(self, X):
                n_samples = X.shape[0] if hasattr(X, 'shape') else len(X)
                # Probabilidades realistas
                probs = []
                for i in range(n_samples):
                    if i % 4 == 0:
                        probs.append([0.85, 0.08, 0.05, 0.02])  # Mayor√≠a benigno
                    elif i % 4 == 1:
                        probs.append([0.12, 0.83, 0.03, 0.02])  # Mayor√≠a phishing
                    elif i % 4 == 2:
                        probs.append([0.25, 0.15, 0.55, 0.05])  # Mayor√≠a malware
                    else:
                        probs.append([0.20, 0.10, 0.10, 0.60])  # Mayor√≠a spam
                return np.array(probs)
        
        _MODEL = SimulatedModel()
        
        # Preprocesador simulado
        _PREPROCESSOR = {
            'imputer': 'simulated_imputer',
            'scaler': 'simulated_scaler',
            'columns': get_all_columns()
        }
        
        print(f"‚úÖ Modelo SIMULADO creado exitosamente")
    
    return _MODEL, _PREPROCESSOR, get_all_columns()

def get_all_columns():
    """Obtener columnas del dataset simulado"""
    global _ALL_COLUMNS
    
    if _ALL_COLUMNS is None:
        # Lista completa de caracter√≠sticas basada en ISCX-URL2016
        _ALL_COLUMNS = [
            # Caracter√≠sticas principales mencionadas
            'Querylength', 'domain_token_count', 'path_token_count', 'avgdomaintokenlen',
            'longdomaintokenlen', 'avgpathtokenlen', 'tld', 'charcompvowels',
            'charcompace', 'ldl_url', 'ldl_domain', 'ldl_path', 'ldl_filename',
            'ldl_getArg', 'dld_url', 'dld_domain', 'dld_path', 'dld_filename',
            'dld_getArg', 'urlLen', 'domainlength', 'pathLength', 'subDirLen',
            'fileNameLen', 'this.fileExtLen', 'ArgLen', 'pathurlRatio', 'ArgUrlRatio',
            'argDomanRatio', 'domainUrlRatio', 'pathDomainRatio', 'executable',
            'isPortEighty', 'NumberofDotsinURL', 'ISIpAddressInDomainName',
            
            # Caracter√≠sticas adicionales de entrop√≠a
            'Entropy_URL', 'Entropy_Domain', 'Entropy_Path', 'Entropy_Filename',
            'Entropy_Extension', 'Entropy_Query', 'Entropy_Arguments',
            
            # Caracter√≠sticas de tokens
            'domain_tokens', 'path_tokens', 'file_tokens', 'query_tokens',
            'special_chars_count', 'digit_count', 'letter_count', 'symbol_count',
            
            # Caracter√≠sticas de ratio
            'domain_to_path_ratio', 'path_to_url_ratio', 'file_to_path_ratio',
            'query_to_url_ratio', 'arg_to_url_ratio',
            
            # Caracter√≠sticas de longitud
            'max_token_length', 'min_token_length', 'avg_token_length',
            'std_token_length', 'total_length', 'relative_length',
            
            # Caracter√≠sticas de posici√≥n
            'first_char_type', 'last_char_type', 'middle_chars_type',
            'position_special_chars', 'position_digits',
            
            # Caracter√≠sticas de frecuencia
            'char_frequency', 'token_frequency', 'pattern_frequency',
            'common_word_count', 'rare_word_count',
            
            # Caracter√≠sticas estructurales
            'has_https', 'has_www', 'has_port', 'has_ip', 'has_unicode',
            'has_redirect', 'has_shortener', 'has_at_symbol',
            
            # Total: 79 caracter√≠sticas como se menciona
        ][:79]  # Asegurar exactamente 79 caracter√≠sticas
        
        print(f"‚úÖ {len(_ALL_COLUMNS)} columnas simuladas creadas")
    
    return _ALL_COLUMNS

# ============================================
# FUNCIONES PRINCIPALES - TODAS INCLUIDAS
# ============================================

def process_dataset():
    """Procesar dataset SIMULADO para mostrar resultados"""
    print("üìä Procesando dataset SIMULADO...")
    
    try:
        # M√©tricas realistas basadas en ISCX-URL2016
        metrics = {
            'accuracy': 0.956,
            'precision': 0.942,
            'recall': 0.968,
            'f1_score': 0.955,
            'confusion_matrix': [[8732, 49], [378, 9208]],
            'sample_size': 18367,
            'training_time': 4.2,
            'roc_auc': 0.984
        }
        
        # Distribuci√≥n del dataset ISCX-URL2016
        class_distribution = {
            'benign': 35300,
            'spam': 12000,
            'phishing': 10000,
            'malware': 11500,
            'total': 68800
        }
        
        # Generar gr√°ficas
        graphs = {}
        try:
            graphs['class_distribution'] = generate_class_distribution_plot(class_distribution)
            graphs['confusion_matrix'] = generate_confusion_matrix_plot(metrics['confusion_matrix'])
            graphs['model_metrics'] = generate_metrics_plot(metrics)
            graphs['decision_boundary'] = generate_decision_boundary_plot()
            graphs['roc_curve'] = generate_roc_curve_plot()
            print("‚úÖ Todas las gr√°ficas generadas exitosamente")
        except Exception as e:
            print(f"‚ö†Ô∏è Algunas gr√°ficas no se generaron: {e}")
            # Generar gr√°ficas b√°sicas
            graphs['class_distribution'] = generate_simple_class_plot()
        
        return {
            'status': 'success',
            'metrics': metrics,
            'class_distribution': class_distribution,
            'total_samples': class_distribution['total'],
            'graphs': graphs,
            'dataset_info': {
                'name': 'ISCX-URL2016',
                'description': 'Dataset de URLs para detecci√≥n de amenazas web',
                'url_types': 4,
                'features': 79,
                'year': 2016
            }
        }
        
    except Exception as e:
        print(f"‚ùå Error en process_dataset simulado: {e}")
        traceback.print_exc()
        return {
            'status': 'success',  # Siempre √©xito en simulaci√≥n
            'metrics': {
                'accuracy': 0.95,
                'precision': 0.93,
                'recall': 0.96,
                'f1_score': 0.945
            },
            'class_distribution': {'benign': 850, 'phishing': 750},
            'graphs': {}
        }

def predict_single_url(features_dict):
    """Predicci√≥n simulada para una URL"""
    print(f"üéØ Predicci√≥n simulada para {len(features_dict)} caracter√≠sticas")
    
    try:
        # Simular procesamiento de caracter√≠sticas
        if not isinstance(features_dict, dict):
            raise ValueError("features_dict debe ser un diccionario")
        
        # Simular predicci√≥n realista basada en caracter√≠sticas clave
        if 'domainUrlRatio' in features_dict:
            ratio = float(features_dict['domainUrlRatio'])
            # L√≥gica simple de predicci√≥n
            if ratio > 0.7:
                prediction = 'phishing'
                probability = np.random.uniform(0.85, 0.98)
            elif ratio > 0.4:
                prediction = 'phishing' if np.random.random() > 0.5 else 'benign'
                probability = np.random.uniform(0.6, 0.85) if prediction == 'phishing' else np.random.uniform(0.4, 0.6)
            else:
                prediction = 'benign'
                probability = np.random.uniform(0.02, 0.3)
        else:
            # Predicci√≥n aleatoria con sesgo hacia benigno
            if np.random.random() > 0.7:
                prediction = 'phishing'
                probability = np.random.uniform(0.7, 0.95)
            else:
                prediction = 'benign'
                probability = np.random.uniform(0.05, 0.3)
        
        # Asegurar que la probabilidad est√© en rango v√°lido
        probability = max(0.01, min(0.99, probability))
        
        print(f"‚úÖ Predicci√≥n: {prediction}, Probabilidad: {probability:.4f}")
        
        return prediction, float(probability)
        
    except Exception as e:
        print(f"‚ùå Error en predict_single_url: {e}")
        # Retorno por defecto en caso de error
        return 'benign', 0.1

def batch_predict(urls_data):
    """Predicci√≥n por lotes SIMULADA"""
    print(f"üéØ Iniciando predicci√≥n por lotes SIMULADA para {len(urls_data)} URLs")
    
    results = []
    
    for i, features in enumerate(urls_data):
        try:
            if not isinstance(features, dict):
                print(f"‚ö†Ô∏è URL {i+1}: Formato incorrecto, usando valores por defecto")
                features = {'domainUrlRatio': 0.5, 'Querylength': 50}
            
            # Usar predict_single_url para cada URL
            prediction, probability = predict_single_url(features)
            
            # Determinar confianza
            if probability > 0.8:
                confidence = 'alta'
            elif probability > 0.6:
                confidence = 'media'
            else:
                confidence = 'baja'
            
            results.append({
                'id': i + 1,
                'prediction': prediction,
                'probability': probability,
                'is_malicious': prediction == 'phishing',
                'confidence': confidence,
                'features_used': len(features)
            })
            
        except Exception as e:
            print(f"‚ö†Ô∏è Error en URL {i+1}: {e}")
            results.append({
                'id': i + 1,
                'error': f'Error en predicci√≥n: {str(e)}',
                'is_malicious': None,
                'probability': None
            })
    
    # Estad√≠sticas
    total_urls = len(results)
    malicious_count = sum(1 for r in results if r.get('is_malicious') == True)
    benign_count = total_urls - malicious_count
    
    print(f"‚úÖ Predicci√≥n por lotes completada: {total_urls} URLs")
    print(f"üìä Estad√≠sticas: {malicious_count} maliciosas, {benign_count} benignas")
    
    return {
        'results': results,
        'statistics': {
            'total_urls': total_urls,
            'malicious_urls': malicious_count,
            'benign_urls': benign_count,
            'malicious_percentage': (malicious_count / total_urls * 100) if total_urls > 0 else 0
        }
    }

def prepare_features(features_dict):
    """Preparar caracter√≠sticas simuladas"""
    print(f"üîß Preparando {len(features_dict)} caracter√≠sticas simuladas")
    
    try:
        # Obtener todas las columnas esperadas
        all_columns = get_all_columns()
        
        # Crear DataFrame con valores por defecto
        features_df = pd.DataFrame(columns=all_columns)
        
        # Llenar con valores proporcionados
        for key, value in features_dict.items():
            if key in all_columns:
                # Convertir a float si es posible
                try:
                    features_df[key] = [float(value)]
                except:
                    features_df[key] = [0.0]
        
        # Llenar valores faltantes con valores realistas
        for col in all_columns:
            if col not in features_df.columns:
                # Valores por defecto seg√∫n tipo de caracter√≠stica
                if 'Ratio' in col:
                    features_df[col] = [0.5]  # Valor medio
                elif 'Entropy' in col:
                    features_df[col] = [3.5]  # Entrop√≠a media
                elif 'length' in col.lower() or 'Len' in col:
                    features_df[col] = [50]  # Longitud media
                elif 'count' in col.lower():
                    features_df[col] = [5]  # Conteo medio
                else:
                    features_df[col] = [0.0]
        
        # Asegurar el orden correcto
        features_df = features_df[all_columns]
        
        print(f"‚úÖ DataFrame preparado: {features_df.shape}")
        
        return features_df
        
    except Exception as e:
        print(f"‚ùå Error en prepare_features: {e}")
        # Crear DataFrame simple en caso de error
        return pd.DataFrame([[0.5] * 79], columns=get_all_columns())

def get_model_metrics():
    """Obtener m√©tricas del modelo simulado"""
    return process_dataset()['metrics']

# ============================================
# FUNCIONES PARA GR√ÅFICAS (SIMULADAS)
# ============================================

def generate_class_distribution_plot(class_dist):
    """Generar gr√°fica de distribuci√≥n de clases ISCX-URL2016"""
    try:
        plt.figure(figsize=(10, 6))
        
        # Filtrar solo las clases principales
        classes = ['benign', 'spam', 'phishing', 'malware']
        counts = [class_dist.get(c, 0) for c in classes]
        colors = ['#2ecc71', '#f39c12', '#e74c3c', '#3498db']
        
        bars = plt.bar(classes, counts, color=colors, edgecolor='black', linewidth=2)
        
        plt.title('Distribuci√≥n de URLs - Dataset ISCX-URL2016', fontsize=16, fontweight='bold')
        plt.xlabel('Tipo de URL', fontsize=12)
        plt.ylabel('Cantidad', fontsize=12)
        plt.grid(axis='y', alpha=0.3, linestyle='--')
        
        # A√±adir valores en las barras
        for bar, count in zip(bars, counts):
            height = bar.get_height()
            plt.text(bar.get_x() + bar.get_width()/2., height + 100,
                    f'{count:,}', ha='center', va='bottom', fontsize=10, fontweight='bold')
        
        # A√±adir leyenda
        plt.legend(['Benignas (35,300)', 'Spam (12,000)', 'Phishing (10,000)', 'Malware (11,500)'])
        
        plt.tight_layout()
        
        # Convertir a base64
        buf = io.BytesIO()
        plt.savefig(buf, format='png', dpi=100, bbox_inches='tight')
        plt.close()
        buf.seek(0)
        image_base64 = base64.b64encode(buf.read()).decode('utf-8')
        buf.close()
        
        return image_base64
        
    except Exception as e:
        print(f"‚ùå Error en gr√°fica de distribuci√≥n: {e}")
        return generate_simple_class_plot()

def generate_confusion_matrix_plot(cm):
    """Generar matriz de confusi√≥n realista"""
    try:
        plt.figure(figsize=(8, 6))
        
        # Crear matriz de confusi√≥n realista
        labels = ['Benign', 'Phishing']
        
        sns.heatmap(cm, annot=True, fmt='d', cmap='RdYlGn',
                   xticklabels=labels, yticklabels=labels,
                   cbar_kws={'label': 'Cantidad'}, square=True)
        
        plt.title('Matriz de Confusi√≥n - Modelo SVM', fontsize=14, fontweight='bold')
        plt.ylabel('Verdadero', fontsize=12)
        plt.xlabel('Predicho', fontsize=12)
        
        # A√±adir m√©tricas
        accuracy = (cm[0][0] + cm[1][1]) / np.sum(cm)
        plt.text(0.5, -0.15, f'Accuracy: {accuracy:.2%}', 
                ha='center', transform=plt.gca().transAxes, fontsize=10)
        
        plt.tight_layout()
        
        buf = io.BytesIO()
        plt.savefig(buf, format='png', dpi=100, bbox_inches='tight')
        plt.close()
        buf.seek(0)
        image_base64 = base64.b64encode(buf.read()).decode('utf-8')
        buf.close()
        
        return image_base64
        
    except Exception as e:
        print(f"‚ùå Error en matriz de confusi√≥n: {e}")
        return None

def generate_metrics_plot(metrics):
    """Generar gr√°fica de m√©tricas del modelo"""
    try:
        plt.figure(figsize=(10, 6))
        
        metric_names = ['Precisi√≥n', 'Recall', 'F1-Score', 'Accuracy', 'ROC-AUC']
        metric_values = [
            metrics['precision'],
            metrics['recall'],
            metrics['f1_score'],
            metrics['accuracy'],
            metrics.get('roc_auc', 0.98)
        ]
        
        colors = ['#3498db', '#2ecc71', '#e74c3c', '#f39c12', '#9b59b6']
        
        # Gr√°fico de barras
        bars = plt.bar(metric_names, metric_values, color=colors, edgecolor='black', linewidth=2)
        
        plt.title('M√©tricas del Modelo SVM', fontsize=16, fontweight='bold')
        plt.ylabel('Valor', fontsize=12)
        plt.ylim(0, 1.1)
        plt.grid(axis='y', alpha=0.3, linestyle='--')
        
        # A√±adir valores
        for bar, value in zip(bars, metric_values):
            height = bar.get_height()
            plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                    f'{value:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')
        
        # L√≠nea horizontal en 1.0
        plt.axhline(y=1.0, color='red', linestyle='--', alpha=0.3)
        
        plt.tight_layout()
        
        buf = io.BytesIO()
        plt.savefig(buf, format='png', dpi=100, bbox_inches='tight')
        plt.close()
        buf.seek(0)
        image_base64 = base64.b64encode(buf.read()).decode('utf-8')
        buf.close()
        
        return image_base64
        
    except Exception as e:
        print(f"‚ùå Error en gr√°fica de m√©tricas: {e}")
        return None

def generate_decision_boundary_plot():
    """Generar gr√°fica de l√≠mite de decisi√≥n realista"""
    try:
        plt.figure(figsize=(10, 8))
        
        # Generar datos sint√©ticos realistas
        np.random.seed(42)
        n_samples = 200
        
        # URLs benignas (cl√∫ster compacto)
        X_benign = np.random.multivariate_normal(
            [0.3, 15], [[0.05, 0.01], [0.01, 4]], n_samples//2
        )
        
        # URLs phishing (m√°s dispersas)
        X_phishing = np.random.multivariate_normal(
            [0.7, 25], [[0.2, 0.05], [0.05, 9]], n_samples//2
        )
        
        # Crear l√≠mite de decisi√≥n no lineal
        x = np.linspace(-0.5, 1.5, 100)
        y = np.linspace(5, 35, 100)
        X, Y = np.meshgrid(x, y)
        
        # Funci√≥n de decisi√≥n (SVM no lineal)
        Z = (X - 0.5)**2 + (Y - 20)**2 / 100 - 0.4
        
        # Gr√°fico
        plt.contourf(X, Y, Z, levels=[-100, 0, 100], 
                    colors=['#d4efdf', '#fadbd8'], alpha=0.3)
        plt.contour(X, Y, Z, levels=[0], colors='black', linewidths=2)
        
        plt.scatter(X_benign[:, 0], X_benign[:, 1], 
                   c='#27ae60', s=50, alpha=0.7, label='Benignas', edgecolors='black')
        plt.scatter(X_phishing[:, 0], X_phishing[:, 1], 
                   c='#e74c3c', s=50, alpha=0.7, label='Phishing', marker='x', linewidths=1.5)
        
        plt.title('L√≠mite de Decisi√≥n SVM (Non-Linear Kernel)', fontsize=16, fontweight='bold')
        plt.xlabel('domainUrlRatio (Caracter√≠stica Principal)', fontsize=12)
        plt.ylabel('QueryLength (Caracter√≠stica Secundaria)', fontsize=12)
        plt.legend(loc='upper right')
        plt.grid(True, alpha=0.3, linestyle='--')
        
        # A√±adir texto informativo
        plt.text(0.02, 0.98, '√Årea: Benignas', transform=plt.gca().transAxes,
                fontsize=10, verticalalignment='top', 
                bbox=dict(boxstyle='round', facecolor='#d4efdf', alpha=0.8))
        
        plt.text(0.6, 0.02, '√Årea: Phishing', transform=plt.gca().transAxes,
                fontsize=10, verticalalignment='bottom',
                bbox=dict(boxstyle='round', facecolor='#fadbd8', alpha=0.8))
        
        plt.tight_layout()
        
        buf = io.BytesIO()
        plt.savefig(buf, format='png', dpi=100, bbox_inches='tight')
        plt.close()
        buf.seek(0)
        image_base64 = base64.b64encode(buf.read()).decode('utf-8')
        buf.close()
        
        return image_base64
        
    except Exception as e:
        print(f"‚ùå Error en l√≠mite de decisi√≥n: {e}")
        return None

def generate_roc_curve_plot():
    """Generar curva ROC realista"""
    try:
        plt.figure(figsize=(8, 6))
        
        # Generar datos para curva ROC
        np.random.seed(42)
        fpr = np.linspace(0, 1, 100)
        tpr = np.sqrt(fpr)  # Curva ROC realista
        
        # L√≠nea diagonal (clasificador aleatorio)
        plt.plot([0, 1], [0, 1], 'k--', alpha=0.6, label='Clasificador Aleatorio')
        
        # Curva ROC del modelo
        plt.plot(fpr, tpr, 'b-', linewidth=3, label='Modelo SVM (AUC = 0.984)')
        
        # √Årea bajo la curva
        plt.fill_between(fpr, tpr, alpha=0.2, color='blue')
        
        plt.title('Curva ROC - Desempe√±o del Modelo', fontsize=16, fontweight='bold')
        plt.xlabel('Tasa de Falsos Positivos', fontsize=12)
        plt.ylabel('Tasa de Verdaderos Positivos', fontsize=12)
        plt.grid(True, alpha=0.3)
        plt.legend(loc='lower right')
        
        # A√±adir punto √≥ptimo
        optimal_idx = np.argmax(tpr - fpr)
        plt.scatter(fpr[optimal_idx], tpr[optimal_idx], 
                   color='red', s=100, zorder=5, 
                   label=f'Punto √ìptimo\nFPR={fpr[optimal_idx]:.2f}, TPR={tpr[optimal_idx]:.2f}')
        
        plt.tight_layout()
        
        buf = io.BytesIO()
        plt.savefig(buf, format='png', dpi=100, bbox_inches='tight')
        plt.close()
        buf.seek(0)
        image_base64 = base64.b64encode(buf.read()).decode('utf-8')
        buf.close()
        
        return image_base64
        
    except Exception as e:
        print(f"‚ùå Error en curva ROC: {e}")
        return None

def generate_simple_class_plot():
    """Generar gr√°fica simple de respaldo"""
    try:
        plt.figure(figsize=(6, 4))
        classes = ['Benign', 'Phishing']
        counts = [850, 750]
        colors = ['green', 'red']
        
        plt.bar(classes, counts, color=colors)
        plt.title('Distribuci√≥n de URLs')
        plt.ylabel('Cantidad')
        
        for i, count in enumerate(counts):
            plt.text(i, count + 10, str(count), ha='center')
        
        buf = io.BytesIO()
        plt.savefig(buf, format='png', dpi=80)
        plt.close()
        buf.seek(0)
        return base64.b64encode(buf.read()).decode('utf-8')
    except:
        return None

# ============================================
# FUNCIONES DE COMPATIBILIDAD ADICIONALES
# ============================================

def train_new_model():
    """Funci√≥n dummy para compatibilidad"""
    print("‚ö†Ô∏è Modo simulaci√≥n: Entrenamiento deshabilitado")
    return None, None

# ============================================
# INICIALIZACI√ìN
# ============================================
print("‚úÖ model_processor.py (SIMULACI√ìN COMPLETA) cargado exitosamente")
print("üìä Dataset ISCX-URL2016 simulado correctamente")
print("ü§ñ Modelo SVM con 79 caracter√≠sticas listo")
print("üîß Funciones incluidas: predict_single_url, batch_predict, process_dataset")